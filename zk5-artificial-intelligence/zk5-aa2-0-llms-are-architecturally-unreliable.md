**`id`**: zk5-aa2-0
**`title`**: llms-are-architecturally-unreliable
**`date`**: 2025-08-10
**`tags`**: #artificial-intelligence #llm #architecture #reliability #reasoning

---

###### Content

-   LLMs are by architecture unreliable because they do not reason and do not understand.
-   We're not getting to AGI by simply scaling current LLM approaches.
-   LLMs work well in text and images but are very sensitive and sparse in other domains.
-   Human decision-making architecture is much more complex than simple neural networks.
-   It would be surprising if LLMs, which are architecturally simpler, could reach AGI when human architecture is much more complex.

###### References

[[zk4-aa7-0-human-purpose-is-knowledge-creation]]
